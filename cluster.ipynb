{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esfMRI import sliceWindows, joint_cluster_save_states, plot_sates, align, clustering_evaluate, windows_evaluate, step_evaluate, AIC, BIC, plot_evaluated\n",
    "from sklearn import cluster, metrics\n",
    "from nilearn import connectome\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可调节参数\n",
    "window_length_Second = [60, 100, 120] # 窗口尺寸，单位s\n",
    "sliding_step = 1 # 滑动步长，单位s\n",
    "target_states = [3, 4, 5, 6] # 目标状态数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 猜测聚类簇数\n",
    "\n",
    "1. 肘点法：绘制inertia随k值变化的曲线，转折幅度最大的点作为簇数。\n",
    "\n",
    "### 评估聚类质量\n",
    "\n",
    "对于不存在已知分类的评价，只能采用内部评价指标  \n",
    "基础参数有\n",
    "1. 紧密度（Compactness）\n",
    "2. 分割度（Seperation）\n",
    "3. 误差平方和（SSE: Sum of squares of errors）\n",
    "\n",
    "评价指标\n",
    "1. 轮廓系数 —— 越大越好\n",
    "2. Calinski-Harabasz Index（CH） —— 越大越好\n",
    "3. Davies-Bouldin Index（DB） —— 越小越好\n",
    "\n",
    "### 模型评估方法\n",
    "\n",
    "1. 贝叶斯信息准则（BIC） —— 越小越好\n",
    "2. 赤池信息量准则（AIC）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入时间序列\n",
    "with open(\"time_series2.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接后聚类评估窗口尺寸影响\n",
    "for subid in data:\n",
    "    for k in target_states:\n",
    "        save_dir = f\"./cluster_evaluate/window_length/joint/{subid}\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        windows_evaluate(data, subid, range(30, 180, 10), 1, k, f\"{save_dir}/{k}_states.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估窗口尺寸，全部数据拼接\n",
    "for k in target_states:\n",
    "    inertias = []\n",
    "    scs = []\n",
    "    chs = []\n",
    "    dbs = []\n",
    "    aic = []\n",
    "    bic = []\n",
    "    for time in range(30, 180, 10):\n",
    "        windows = []\n",
    "        for subid in data:\n",
    "            for run, items in data[subid][\"ses-preop\"].items():\n",
    "                preopTR = math.ceil(time/items[\"TR\"])\n",
    "                windows += sliceWindows(items[\"time_series\"], preopTR, 2)\n",
    "            for run, items in data[subid][\"ses-postop\"].items():\n",
    "                postopTR = math.ceil(time/items[\"TR\"])\n",
    "                windows += sliceWindows(items[\"time_series\"], postopTR, 2)\n",
    "        fcs = connectome.ConnectivityMeasure(kind=\"correlation\").fit_transform(windows)\n",
    "        del windows\n",
    "        fcs = fcs.reshape((fcs.shape[0], 13456))\n",
    "        if k < fcs.shape[0]:\n",
    "            center, states, inertia = cluster.k_means(fcs, k)\n",
    "            inertias.append(inertia) # 肘点法\n",
    "            scs.append(metrics.silhouette_score(fcs, states)) # 轮廓系数\n",
    "            chs.append(metrics.calinski_harabasz_score(fcs, states)) # CH，方差比\n",
    "            dbs.append(metrics.davies_bouldin_score(fcs, states)) # DB\n",
    "            aic.append(AIC(fcs.shape[0], k, inertia))\n",
    "            bic.append(BIC(fcs.shape[0], k, inertia))\n",
    "        else:\n",
    "            inertias.append(inertias[-1])\n",
    "            scs.append(scs[-1])\n",
    "            chs.append(chs[-1])\n",
    "            dbs.append(dbs[-1])\n",
    "            aic.append(aic[-1])\n",
    "            bic.append(bic[-1])\n",
    "        del fcs\n",
    "    # 绘图\n",
    "    plot_evaluated(range(30, 180, 10), inertias=inertias, scs=scs, chs=chs, dbs=dbs, aic=aic, bic=bic, save_path=f\"cluster_evaluate/window_length/total/{k}_states.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接后聚类评估步长影响\n",
    "for subid in data:\n",
    "    for time in window_length_Second:\n",
    "        # if time != 150:\n",
    "        #     continue\n",
    "        for k in target_states:\n",
    "            save_dir = f\"cluster_evaluate/joint/{subid}/{k}_states\"\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            step_evaluate(time, range(1, 10), k, save_dir, data[subid][\"ses-preop\"], data[subid][\"ses-postop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全部拼接后聚类评估步长影响\n",
    "time_series_preop = {}\n",
    "time_series_postop = {}\n",
    "for subid in data:\n",
    "    for run, items in data[subid][\"ses-preop\"].items():\n",
    "        time_series_preop[f\"{subid}-{run}\"] = items\n",
    "    for run, items in data[subid][\"ses-postop\"].items():\n",
    "        time_series_postop[f\"{subid}-{run}\"] = items\n",
    "step_evaluate(120, range(1, 10), 3, \"cluster_evaluate/step\", time_series_preop, time_series_postop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接后聚类评估\n",
    "for subid in data:\n",
    "    for time in window_length_Second:\n",
    "        # if time != 150:\n",
    "        #     continue\n",
    "        windows_preop = []\n",
    "        windows_postop = []\n",
    "        for run, items in data[subid][\"ses-preop\"].items():\n",
    "            intervalFrame = math.ceil(sliding_step/items[\"TR\"])\n",
    "            preopFrame = math.ceil(time/items[\"TR\"])\n",
    "            tmp = sliceWindows(items[\"time_series\"], preopFrame, intervalFrame)\n",
    "            windows_preop += tmp\n",
    "        for run, items in data[subid][\"ses-postop\"].items():\n",
    "            intervalFrame = math.ceil(sliding_step/items[\"TR\"])\n",
    "            postopFrame = math.ceil(time/items[\"TR\"])\n",
    "            tmp = sliceWindows(items[\"time_series\"], postopFrame, intervalFrame)\n",
    "            windows_postop += tmp\n",
    "        save_dir = f\"cluster_evaluate/joint/{subid}/\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        clustering_evaluate(windows_preop, range(2, 15), f\"{save_dir}/preop_{time}.png\")\n",
    "        clustering_evaluate(windows_postop, range(2, 15), f\"{save_dir}/postop_{time}.png\")\n",
    "        clustering_evaluate(windows_preop+windows_postop, range(2, 15), f\"{save_dir}/total_{time}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个被试分别聚类，输出状态变化\n",
    "for subid in data:\n",
    "    states = {}\n",
    "    for time in window_length_Second:\n",
    "        # if time != 150:\n",
    "        #     continue\n",
    "        states[time] = {}\n",
    "        preopFrame = math.ceil(time/data[subid][\"ses-preop\"][\"run-01\"][\"TR\"])\n",
    "        postopFrame = math.ceil(time/data[subid][\"ses-postop\"][\"run-01\"][\"TR\"])\n",
    "        windows_preop = []\n",
    "        windows_postop = []\n",
    "        window_length_preop = []\n",
    "        window_length_postop = []\n",
    "        for run, items in data[subid][\"ses-preop\"].items():\n",
    "            tmp = sliceWindows(items[\"time_series\"], preopFrame, 1)\n",
    "            window_length_preop.append(len(tmp))\n",
    "            windows_preop += tmp\n",
    "        for run, items in data[subid][\"ses-postop\"].items():\n",
    "            tmp = sliceWindows(items[\"time_series\"], postopFrame, 1)\n",
    "            window_length_postop.append(len(tmp))\n",
    "            windows_postop += tmp\n",
    "        states[time][\"length\"] = [window_length_preop, window_length_postop]\n",
    "        for k in target_states:\n",
    "            states_k = joint_cluster_save_states(windows_preop, windows_postop, k)\n",
    "            states[time][\"preop\"] = states_k[0]\n",
    "            states[time][\"postop\"] = states_k[1]\n",
    "            save_dir = f\"states_pkl/joint/{subid}\"\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            with open(f\"{save_dir}/{k}states.pkl\", \"wb\") as f:\n",
    "                pickle.dump(states, f)\n",
    "\n",
    "            save_dir = f\"states/joint/{k}states/{time}/{subid}/\"\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            plot_sates(states[time][\"preop\"], f\"{save_dir}/preop.png\")\n",
    "            plot_sates(states[time][\"postop\"], f\"{save_dir}/postop.png\")\n",
    "            tmp = 0\n",
    "            for run,length in enumerate(states[time][\"length\"][0]):\n",
    "                plot_sates(states[time][\"preop\"][tmp:tmp+length], f\"{save_dir}/preop_run{run+1:0>2d}.png\")\n",
    "                tmp += length\n",
    "            tmp = 0\n",
    "            for run,length in enumerate(states[time][\"length\"][1]):\n",
    "                plot_sates(states[time][\"postop\"][tmp:tmp+length], f\"{save_dir}/postop_run{run+1:0>2d}.png\")\n",
    "                tmp += length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有人平均后聚类\n",
    "# 对齐帧数\n",
    "align_length_preop = 130\n",
    "align_length_postop = 200\n",
    "\n",
    "time_series_preop = None\n",
    "time_series_postop = None\n",
    "count_preop = 0\n",
    "count_postop = 0\n",
    "for subid in data:\n",
    "    for run, items in data[subid][\"ses-preop\"].items():\n",
    "        if items[\"time_series\"].shape[0] < align_length_preop:\n",
    "            continue\n",
    "        count_preop += 1\n",
    "        time_series_preop = align(items[\"time_series\"], align_length_preop) if time_series_preop is None else time_series_preop + align(items[\"time_series\"], align_length_preop)\n",
    "    for run, items in data[subid][\"ses-postop\"].items():\n",
    "        if items[\"time_series\"].shape[0] < align_length_postop:\n",
    "            continue\n",
    "        count_postop += 1\n",
    "        time_series_postop = align(items[\"time_series\"], align_length_postop) if time_series_postop is None else time_series_postop + align(items[\"time_series\"], align_length_postop)\n",
    "time_series_preop = time_series_preop/count_preop\n",
    "time_series_postop = time_series_postop/count_postop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体数据平均后，评估窗口尺寸影响\n",
    "inertias = []\n",
    "scs = []\n",
    "chs = []\n",
    "dbs = []\n",
    "aic = []\n",
    "bic = []\n",
    "for time in range(30, 180, 10):\n",
    "    windows_preop = sliceWindows(time_series_preop, math.ceil(time/2.26), 1)\n",
    "    windows_postop = sliceWindows(time_series_postop, math.ceil(time/3), 1)\n",
    "    windows = windows_preop + windows_postop\n",
    "    fcs = connectome.ConnectivityMeasure(kind=\"correlation\").fit_transform(windows)\n",
    "    fcs = fcs.reshape((fcs.shape[0], 13456))\n",
    "    if k < fcs.shape[0]:\n",
    "        center, states, inertia = cluster.k_means(fcs, k)\n",
    "        inertias.append(inertia) # 肘点法\n",
    "        scs.append(metrics.silhouette_score(fcs, states)) # 轮廓系数\n",
    "        chs.append(metrics.calinski_harabasz_score(fcs, states)) # CH，方差比\n",
    "        dbs.append(metrics.davies_bouldin_score(fcs, states)) # DB\n",
    "        aic.append(AIC(fcs.shape[0], k, inertia))\n",
    "        bic.append(BIC(fcs.shape[0], k, inertia))\n",
    "    else:\n",
    "        inertias.append(inertias[-1])\n",
    "        scs.append(scs[-1])\n",
    "        chs.append(chs[-1])\n",
    "        dbs.append(dbs[-1])\n",
    "        aic.append(aic[-1])\n",
    "        bic.append(bic[-1])\n",
    "plot_evaluated(range(30, 180, 10), inertias=inertias, scs=scs, chs=chs, dbs=dbs, aic=aic, bic=bic, save_path=\"cluster_evaluate/window_length/average.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体数据平均，绘制状态变化\n",
    "states = {}\n",
    "for time in window_length_Second:\n",
    "    states[time] = {}\n",
    "    preopTR = math.ceil(time/data[subid][\"ses-preop\"][\"run-01\"][\"TR\"])\n",
    "    postopTR = math.ceil(time/data[subid][\"ses-postop\"][\"run-01\"][\"TR\"])\n",
    "    windows_preop = sliceWindows(time_series_preop, preopTR, 1)\n",
    "    windows_postop = sliceWindows(time_series_postop, postopTR, 1)\n",
    "    for k in target_states:\n",
    "        if len(windows_preop) <= k and len(windows_postop) <= k:\n",
    "            continue\n",
    "        states_k = joint_cluster_save_states(windows_preop, windows_postop, k)\n",
    "        states[time][\"preop\"] = states_k[0]\n",
    "        states[time][\"postop\"] = states_k[1]\n",
    "        save_dir = f\"states_pkl/average/\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        with open(f\"{save_dir}/{k}states.pkl\", \"wb\") as f:\n",
    "            pickle.dump(states, f)\n",
    "\n",
    "        save_dir = f\"states/average/{k}states/{time}/\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        plot_sates(states[time][\"preop\"], k, f\"{save_dir}/preop.png\")\n",
    "        plot_sates(states[time][\"postop\"], k, f\"{save_dir}/postop.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"slidingWindows.pkl\", \"rb\") as f:\n",
    "    slidingWindows = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接后聚类评估\n",
    "windows_preop = []\n",
    "windows_postop = []\n",
    "save_path = \"cluster_evaluate/total\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "time = 180\n",
    "for subid in slidingWindows:\n",
    "        windows_preop += slidingWindows[subid][\"ses-preop\"][\"total\"]\n",
    "        windows_postop += slidingWindows[subid][\"ses-postop\"][\"total\"]\n",
    "clustering_evaluate(windows_preop, range(2, 15), f\"{save_path}/{time}_preop.png\")\n",
    "clustering_evaluate(windows_postop, range(2, 15), f\"{save_path}/{time}_postop.png\")\n",
    "clustering_evaluate(windows_preop+windows_postop, range(2, 15), f\"{save_path}/{time}_total.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dFC/60_3dFCs.pkl\", \"rb\") as f:\n",
    "    dFCs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体拼接后聚类，输出状态变化\n",
    "save_path = \"states/total\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "time = 60\n",
    "dfcs_preop = None\n",
    "dfcs_postop = None\n",
    "for subid in dFCs:\n",
    "    # preop\n",
    "    if \"total\" in dFCs[subid][\"ses-preop\"]:\n",
    "        if dfcs_preop is None:\n",
    "            dfcs_preop = dFCs[subid][\"ses-preop\"][\"total\"].reshape((dFCs[subid][\"ses-preop\"][\"total\"].shape[0], 13456))\n",
    "        else:\n",
    "            dfcs_preop = np.vstack((dfcs_preop, dFCs[subid][\"ses-preop\"][\"total\"].reshape((dFCs[subid][\"ses-preop\"][\"total\"].shape[0], 13456))))\n",
    "    else:\n",
    "        for run in dFCs[subid][\"ses-preop\"]:\n",
    "            if dfcs_preop is None:\n",
    "                dfcs_preop = dFCs[subid][\"ses-preop\"][run].reshape((dFCs[subid][\"ses-preop\"][run].shape[0], 13456))\n",
    "            else:\n",
    "                dfcs_preop = np.vstack((dfcs_preop, dFCs[subid][\"ses-preop\"][run].reshape((dFCs[subid][\"ses-preop\"][run].shape[0], 13456))))\n",
    "    # postop\n",
    "    if \"total\" in dFCs[subid][\"ses-postop\"]:\n",
    "        if dfcs_postop is None:\n",
    "            dfcs_postop = dFCs[subid][\"ses-postop\"][\"total\"].reshape((dFCs[subid][\"ses-postop\"][\"total\"].shape[0], 13456))\n",
    "        else:\n",
    "            dfcs_postop = np.vstack((dfcs_postop, dFCs[subid][\"ses-postop\"][\"total\"].reshape((dFCs[subid][\"ses-postop\"][\"total\"].shape[0], 13456))))\n",
    "    else:\n",
    "        for run in dFCs[subid][\"ses-postop\"]:\n",
    "            if dfcs_postop is None:\n",
    "                dfcs_postop = dFCs[subid][\"ses-postop\"][run].reshape((dFCs[subid][\"ses-postop\"][run].shape[0], 13456))\n",
    "            else:\n",
    "                dfcs_postop = np.vstack((dfcs_postop, dFCs[subid][\"ses-postop\"][run].reshape((dFCs[subid][\"ses-postop\"][run].shape[0], 13456))))\n",
    "\n",
    "# 释放内存\n",
    "del dFCs\n",
    "fcs = np.vstack((dfcs_preop, dfcs_postop))\n",
    "# 释放内存，懒得改上面的\n",
    "del dfcs_preop\n",
    "del dfcs_postop\n",
    "\n",
    "# 保存聚类对象\n",
    "for k in target_states:\n",
    "    # if k == 3:\n",
    "    #     continue\n",
    "    km = cluster.KMeans(k)\n",
    "    km.fit(fcs)\n",
    "    save_dir = f\"{save_path}/cluster\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    with open(f\"{save_dir}/km_{time}s_{k}states.pkl\", \"wb\") as f:\n",
    "        pickle.dump(km, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14da249aea668dd476485a6222a8c1fd2f2cd90c7005afa5442c69b6c853f2dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
